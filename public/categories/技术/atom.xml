<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on 凝雨 - Yun</title>
    <link>https://ningyu1.github.io/site/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 凝雨 - Yun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jul 2017 15:22:56 +0000</lastBuildDate>
    
	<atom:link href="https://ningyu1.github.io/site/categories/%E6%8A%80%E6%9C%AF/atom.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Lombok使用说明</title>
      <link>https://ningyu1.github.io/site/post/04-lombok-quick-start/</link>
      <pubDate>Wed, 19 Jul 2017 15:22:56 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/04-lombok-quick-start/</guid>
      <description>一、项目背景 在写Java程序的时候经常会遇到如下情形：
新建了一个Class类，然后在其中设置了几个字段，最后还需要花费很多时间来建立getter和setter方法
lombok项目的产生就是为了省去我们手动创建getter和setter方法的麻烦，它能够在我们编译源码的时候自动帮我们生成getter和setter方法。即它最终能够达到的效果是：在源码中没有getter和setter方法，但是在编译生成的字节码文件中有getter和setter方法
比如源码文件：
import java.io.Serializable; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import lombok.extern.slf4j.Slf4j; @Data @Slf4j @NoArgsConstructor @AllArgsConstructor public class TestUserVo implements Serializable{ private static final long serialVersionUID = -5648809805573016853L; private Long id; private Long userId; /** * 获取 id * @return the id */ public Long getId() { System.out.println(&amp;quot;getId&amp;quot;); return id; } /** * 设置 id * @param id the id to set */ public void setId(Long id) { System.</description>
    </item>
    
    <item>
      <title>Fastdfs安装说明与常见问题解决</title>
      <link>https://ningyu1.github.io/site/post/02-fastdfs-installer/</link>
      <pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/02-fastdfs-installer/</guid>
      <description>Fastdfs安装说明与常见问题解决 docker中安装 docker pull season/fastdfs docker tag season/fastdfs 192.168.0.34:5000/season/fastdfs docker push 192.168.0.34:5000/season/fastdfs  启动会获取tracker ip 192.168.0.54:22122
monitor检测
/usr/local/bin/fdfs_monitor /etc/fdfs/storage.conf  storage store_path0路径与base_path路径必须不同
物理机安装 1.安装git yum install -y git
2.下载fastdfs源码 git clone https://github.com/happyfish100/fastdfs.git git clone https://github.com/happyfish100/libfastcommon.git git clone https://github.com/happyfish100/fastdfs-nginx-module.git  3.下载nginx cp /home/jyftp/nginx-1.10.1.tar.gz ./ tar -xvf nginx-1.10.1.tar.gz rm -rf nginx-1.10.1.tar.gz chown -R root.root nginx-1.10.1/ mv nginx-1.10.1/ nginx  4.安装libfastcommon (fastdfs依赖的系统库） cd /usr/local/fastdfs/libfastcommon ./make.sh ./make.sh install  5.安装fastdfs cd /usr/local/fastdfs/fastdfs ./make.sh .</description>
    </item>
    
    <item>
      <title>Nginx 502 Bad Gateway问题分析与踩过的坑</title>
      <link>https://ningyu1.github.io/site/post/03-nginx-502-bad-gateway/</link>
      <pubDate>Fri, 30 Jun 2017 18:36:44 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/03-nginx-502-bad-gateway/</guid>
      <description>我相信使用Nginx的都会遇到过502 504 这种bad gateway错误，下面我把碰到这个问题分析过程记录并分享出来。 先让我们看一下具体的错误信息
502 Bad Gateway The proxy server received an invalid response from an upstream server  从字面上的意思理解，nginx从upstream没有接受到信息，第一感觉就是连接被close？还是超时了？超时的话一般错误信息是 timeout
下面是尝试解决这个问题尝试过的手段
1. 第一感觉是proxy返回超时，因此查找nginx官方文档，找到关于proxy的timeout设置 Syntax: proxy_connect_timeout time; Default: proxy_connect_timeout 60s; Context: http, server, location Defines a timeout for establishing a connection with a proxied server. It should be noted that this timeout cannot usually exceed 75 seconds.  ps. 这个时间不能超过75秒
Syntax: proxy_read_timeout time; Default: proxy_read_timeout 60s; Context: http, server, location Defines a timeout for reading a response from the proxied server.</description>
    </item>
    
    <item>
      <title>Cache设计和使用上的套路</title>
      <link>https://ningyu1.github.io/site/post/05-cache-design/</link>
      <pubDate>Fri, 02 Jun 2017 14:06:34 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/05-cache-design/</guid>
      <description>一、管道（pipeline）提升效率 Redis是一个cs模式的tcp server，使用和http类似的请求响应协议。一个client可以通过一个socket连接发起多个请求命令。每个请求命令发出后client通常会阻塞并等待redis服务处理，redis处理完后请求命令后会将结果通过响应报文返回给client。每执行一个命令需要2个tcp报文才能完成，由于通信会有网络延迟,假如从client和server之间的包传输时间需要0.125秒，那么执行四个命令8个报文至少会需要1秒才能完成，这样即使redis每秒能处理100k命令，而我们的client也只能一秒钟发出四个命令。这显示没有充分利用 redis的处理能力。因此我们需要使用管道（pipeline）的方式从client打包多条命令一起发出，不需要等待单条命令的响应返回，而redis服务端会处理完多条命令后会将多条命令的处理结果打包到一起返回给客户端（它能够让（多条）执行命令简单的，更加快速的发送给服务器，但是没有任何原子性的保证）官方资料
【反例】
【正例】
//管道，批量发送多条命令，但是不支持namespace需要手动添加namespace Pipeline pipelined = redisClient.pipelined(); pipelined.set(key, value); pipelined.get(key); pipelined.syncAndReturnAll(); //发送命令并接受返回值 pipelined.sync();//发送命令不接受返回值  使用管道注意事项： 1. tcp报文过长会被拆分。 2. 如果使用pipeline服务器会被迫使用内存队列来发送应答（服务器会在处理完命令前先缓存所有的命令处理结果） 3. 打包的命令越多，缓存消耗内存也越多，所以并不是打包命令越多越好，需要结合测试找到合适我们业务场景的量（双刃剑） 4. 不保证原子性，因此在Redis中没有数据需要走DB获取数据，Redis也支持事务（multi、watch）但是会影响性能（没有事务和有事务相差还是蛮大的），不是非要强一致的场景请不要使用。
二、连接池使用问题 jedis客户端2.4版本以上对连接池资源使用上进行了优化，提供了更优雅的资源回收方法并且支持broken处理，提供close方法替换原来的回收资源方法（returnBrokenResource 、returnResource）
【反例】
【正例】
三、使用key值前缀来作命名空间 虽然说Redis支持多个数据库（默认32个，可以配置更多），但是除了默认的0号库以外，其它的都需要通过一个额外请求才能使用。所以用前缀作为命名空间可能会更明智一点。另外，在使用前缀作为命名空间区隔不同key的时候，最好在程序中使用全局配置来实现，直接在代码里写前缀的做法要严格避免，这样可维护性实在太差了。
命名分割符使用 “.” 分隔
【正例】
四、expire对于key过期时间来控制垃圾回收 Redis是一个提供持久化功能的内存数据库，如果你不指定上面值的过期时间（TTL），并且也不进行定期的清理工作，那么你的Redis内存占用会越来越大，当有一天它超过了系统可用内存，那么swap上场，离性能陡降的时间就不远了。所以在Redis中保存数据时，一定要预先考虑好数据的生命周期，这有很多方法可以实现。
比如你可以采用Redis自带的过期时间（setEX）为你的数据设定过期时间。但是自动过期有一个问题，很有可能导致你还有大量内存可用时，就让key过期去释放内存，或者是内存已经不足了key还没有过期。
（LRU）如果你想更精准的控制你的数据过期，你可以用一个ZSET来维护你的数据更新程度，你可以用时间戳作为score值，每次更新操作时更新一下score，这样你就得到了一个按更新时间排序序列串，你可以轻松地找到最老的数据，并且从最老的数据开始进行删除，一直删除到你的空间足够为止。
【正例】
redisClient.setex(bizkey, 60, value);//set一个key并设置ttl60秒  五、乱用（不要有个锤子看哪都是钉子） 当你使用Redis构建你的服务的时候，一定要记住，你只是找了一个合适的工具来实现你需要的功能。而不是说你在用Redis构建一个服务，这是很不同的，你把Redis当作你很多工具中的一个，只在合适使用的时候再使用它，在不合适的时候选择其它的方法。
我们对它的定位更多是Cache服务而非DB
六、缓存设计的误区 我们通常是这样设计的，应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
那试想一下，如果取出来的null，需不需要放入cache呢？答案当然是需要的。
我们试想一下如果取出为null不放入cache会有什么结果？很显然每次取cache没有走db返回null，很容易让攻击者利用这个漏洞搞垮你的服务器，利用洪水攻击让你的程序夯在这个地方导致你的正常流程抢不到资源。
七、缓存更新的问题 很多人在写更新缓存数据代码时，先删除缓存，然后再更新数据库，而后续的操作会把数据再装载的缓存中。然而，这个是逻辑是错误的。试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。
正确更新缓存的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching
Cache Aside Pattern</description>
    </item>
    
    <item>
      <title>ActiveMQ使用经验分享，配置详解</title>
      <link>https://ningyu1.github.io/site/post/06-activemq-settings/</link>
      <pubDate>Thu, 11 May 2017 12:03:10 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/06-activemq-settings/</guid>
      <description>根据我们的使用场景抽取出来了一系列activemq公共配置参数mq.properties
mq.properties activemq.connnect.brokerurl=failover:(tcp://192.168.0.66:61616) activemq.connnect.useAsyncSend=true # object对象接受报名单,true不受限制,false需要设置白名单 activemq.connnect.trustAllPackages=true # 最大连接数 activemq.pool.maxConnections=20 # 空闲失效时间,毫秒 activemq.pool.idleTimeout=60000 # 初始数量 activemq.listener.pool.corePoolSize=5 activemq.listener.pool.maxPoolSize=10 # 启动守护进程 activemq.listener.pool.daemon=true # 单位秒 activemq.listener.pool.keepAliveSeconds=120 # 由于jms:listener-container不支持propertyPlaceholder替换，因此这些参数值写在spring-mq.xml文件中，参考值 # # 接收消息时的超时时间,单位毫秒 activemq.consumer.receiveTimeout=60000 # 监听目标类型 activemq.listener.destinationtype=queue # 监听确认消息方式 activemq.listener.acknowledge=auto # 监听数量 activemq.listener.concurrency=2-10  spring-mq.xml &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;beans xmlns=&amp;quot;http://www.springframework.org/schema/beans&amp;quot; xmlns:context=&amp;quot;http://www.springframework.org/schema/context&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xmlns:amq=&amp;quot;http://activemq.apache.org/schema/core&amp;quot; xmlns:jms=&amp;quot;http://www.springframework.org/schema/jms&amp;quot; xsi:schemaLocation=&amp;quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms-4.0.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.8.0.xsd&amp;quot;&amp;gt; &amp;lt;!-- 配置activeMQ连接 tcp://192.168.0.66:61616 --&amp;gt; &amp;lt;bean id=&amp;quot;targetConnectionFactory&amp;quot; class=&amp;quot;org.apache.activemq.ActiveMQConnectionFactory&amp;quot;&amp;gt; &amp;lt;property name=&amp;quot;brokerURL&amp;quot; value=&amp;quot;${activemq.connnect.brokerurl}&amp;quot; /&amp;gt; &amp;lt;!-- useAsyncSend 异步发送 --&amp;gt; &amp;lt;property name=&amp;quot;useAsyncSend&amp;quot; value=&amp;quot;${activemq.</description>
    </item>
    
    <item>
      <title>Maven settings.xml详解</title>
      <link>https://ningyu1.github.io/site/post/07-maven-settings/</link>
      <pubDate>Wed, 10 May 2017 10:05:37 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/07-maven-settings/</guid>
      <description>settings.xml有什么用 从settings.xml的文件名就可以看出，它是用来设置maven参数的配置文件。并且，settings.xml是maven的全局配置文件。而pom.xml文件是所在项目的局部配置。
Settings.xml中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。
settings.xml文件位置 全局配置: ${M2_HOME}/conf/settings.xml
用户配置: user.home/.m2/settings.xmlnote：用户配置优先于全局配置。user.home/.m2/settings.xmlnote：用户配置优先于全局配置。{user.home} 和和所有其他系统属性只能在3.0+版本上使用。请注意windows和Linux使用变量的区别。
配置优先级 需要注意的是：局部配置优先于全局配置。
配置优先级从高到低：pom.xml&amp;gt; user settings &amp;gt; global settings
如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。
ps.修改了配置文件最好吧cmd和eclipse重开一下
settings.xml元素详解 顶级元素概览 下面列举了settings.xml中的顶级元素
&amp;lt;settings xmlns=&amp;quot;http://maven.apache.org/SETTINGS/1.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xsi:schemaLocation=&amp;quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&amp;quot;&amp;gt; &amp;lt;localRepository/&amp;gt; &amp;lt;interactiveMode/&amp;gt; &amp;lt;usePluginRegistry/&amp;gt; &amp;lt;offline/&amp;gt; &amp;lt;pluginGroups/&amp;gt; &amp;lt;servers/&amp;gt; &amp;lt;mirrors/&amp;gt; &amp;lt;proxies/&amp;gt; &amp;lt;profiles/&amp;gt; &amp;lt;activeProfiles/&amp;gt; &amp;lt;/settings&amp;gt;  LocalRepository 作用：该值表示构建系统本地仓库的路径。
其默认值：~/.m2/repository。 &amp;lt;localRepository&amp;gt;${user.home}/.m2/repository&amp;lt;/localRepository&amp;gt;
InteractiveMode 作用：表示maven是否需要和用户交互以获得输入。
如果maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。 &amp;lt;interactiveMode&amp;gt;true&amp;lt;/interactiveMode&amp;gt;
UsePluginRegistry 作用：maven是否需要使用plugin-registry.xml文件来管理插件版本。
如果需要让maven使用文件~/.m2/plugin-registry.xml来管理插件版本，则设为true。默认为false。 &amp;lt;usePluginRegistry&amp;gt;false&amp;lt;/usePluginRegistry&amp;gt;
Offline 作用：表示maven是否需要在离线模式下运行。
如果构建系统需要在离线模式下运行，则为true，默认为false。
当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。 &amp;lt;offline&amp;gt;false&amp;lt;/offline&amp;gt;
PluginGroups 作用：当插件的组织id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。
该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。
当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins和org.codehaus.mojo。
&amp;lt;settings xmlns=&amp;quot;http://maven.apache.org/SETTINGS/1.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xsi:schemaLocation=&amp;quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&amp;quot;&amp;gt; ... &amp;lt;pluginGroups&amp;gt; &amp;lt;!--plugin的组织Id（groupId） --&amp;gt; &amp;lt;pluginGroup&amp;gt;org.</description>
    </item>
    
    <item>
      <title>RESTful设计规范</title>
      <link>https://ningyu1.github.io/site/post/01-restful-design-specifications/</link>
      <pubDate>Tue, 21 Feb 2017 11:58:19 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/01-restful-design-specifications/</guid>
      <description>一、 摘要（Abstract） RESTful API 已经非常成熟，也得到了大家的认可。我们按照 Richardson Maturity Model 对 REST 评价的模型，规范基于 level2 来设计
二、版本（Versioning） API的版本号放入URL。例如：
https://api.jiuyescm.com/v1/ https://api.jiuyescm.com/v1.2/  三、资源、路径（Endpoint） 路径，API的具体地址。在REST中，每个地址都代表一个具体的资源（Resource）约定如下：
 路径仅表示资源的路径（位置），尽量不要有actions操作（一些特殊的actions操作除外） 路径以 复数（名词） 进行命名资源，不管返回单个或者多个资源。 使用 小写字母、数字以及下划线（“_”） 。（下划线是为了区分多个单词，如user_name） 资源的路径从父到子依次如：
/{resource}/{resource_id}/{sub_resource}/{sub_resource_id}/{sub_resource_property}  使用 ? 来进行资源的过滤、搜索以及分页等
 使用版本号，且版本号在资源路径之前
 优先使用内容协商来区分表述格式，而不是使用后缀来区分表述格式
 应该放在一个专用的域名下，如：http：//api.jiuyescm.com
 使用SSL
  综上，一个API路径可能会是
https://api.domain.com/v1/{resource}/{resource_id}/{sub_resource}/{sub_resource_id}/{sub_resource_property} https://api.domain.com /v1/{resource}?page=1&amp;amp;page_size=10 https://api.domain.com /v1/{resource}?name=xx&amp;amp;sortby=name&amp;amp;order=asc  四、操作（HTTP Actions） 用HTTP动词（方法）表示对资源的具体操作。常用的HTTP动词有：
GET（SELECT）：从服务器取出资源（一项或多项） POST（CREATE）：在服务器新建一个资源 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源） PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性） DELETE（DELETE）：从服务器删除资源 还有两个不常用的HTTP动词 HEAD：获取资源的元数据 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的  下面是一些例子
GET /users：列出所有用户 POST /users：新建一个用户 GET /users/{user_id}：获取某个指定用户的信息 PUT /users/{user_id}：更新某个指定用户的信息（提供该用户的全部信息） PATCH /users/{user_id}：更新某个指定用户的信息（提供该用户的部分信息） DELETE /users/{user_id}：删除某个用户 GET /users/{user_id}/resources：列出某个指定用户的所有权限资源 DELETE /users/{user_id}/resources/{resources_id}：删除某个指定用户的指定权限资源  五、数据（Data Format） 数据是对资源的具体描述，分为请求数据和返回数据。约定如下：</description>
    </item>
    
    <item>
      <title>Dubbo本地调试最优方式，本地Server端调用本地Client端</title>
      <link>https://ningyu1.github.io/site/post/09-dubbo-debug/</link>
      <pubDate>Tue, 20 Dec 2016 14:32:41 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/09-dubbo-debug/</guid>
      <description>分布式应用的调试总是比常规项目开发调试起来要麻烦很多。 我们还在为搞不清自己请求的服务是本地服务还是服务器服务而苦恼吗？ 我们还在为配置文件被修改导致服务器上版本服务不正常而苦恼吗？ 接下来我介绍一个Dubbo在多环境调试的最优调试方式，在介绍之前先说一下我们现在的调试方式。
不好的方式（现在的方式）： 现在本地调试，需要修改DubboServer.xml和DubboClient.xml配置文件
将文件中的 dubbo:registry protocol=&amp;quot;zookeeper&amp;quot; address=&amp;quot;${dubbo.registry}&amp;quot; /&amp;gt; 修改为 &amp;lt;dubbo:registry address=&amp;quot;N/A&amp;quot; /&amp;gt;  这种方式的弊端：
 开发总是不注意将修改为address=&amp;ldquo;N/A&amp;rdquo;的文件提交到svn，在其他环境打包run起来，总是没有Export Service。 文件经常被改来改去容易冲突，冲突解决不好容易丢失配置。 无法很好的将本地调试和各环境的相互依赖分离开  最优的方式：
 创建一个properties文件，名字可以随便命名，我命名为：dubbo-local.properties，这个文件可以放在任何地方。该文件不提交到svn，我建议不要放在工程目录里以避免自己提交了都不知道，建议放在用户目录下${user.home}(不知道用户目录的自己去 度娘、谷哥、必硬) dubbo-local.properties文件内容如下：
&amp;lt;!--注册中心变量 --&amp;gt; dubbo.registry=N/A &amp;lt;!--以下是你们DubboServer.xml中配置的需要Export Service，这里我建议你有几个要Export Service都配置在这里，后面是请求本地的地址 地址格式：dubbo://ip:port，这里需要注意的是，需要修改为自己dubbo服务的端口 --&amp;gt; com.domain.imprest.api.IImprestRecordService=dubbo://localhost:20812 com.domain.imprest.api.IImprestRequestService=dubbo://localhost:20812 com.domain.imprest.api.IImprestTrackService=dubbo://localhost:20812 com.domain.imprest.api.IImprestWriteoffService=dubbo://localhost:20812 com.domain.imprest.api.IImprestIOCollectService=dubbo://localhost:20812 com.domain.imprest.api.ISystemService=dubbo://localhost:20812 com.domain.imprest.api.IImprestDeptService=dubbo://localhost:20812  接下来启动你的Dubbo服务，在启动之前需要添加一下启动参数
  参数：-Ddubbo.properties.file 值：dubbo-local.properties文件的本地地址，绝对地址   接下来启动你的web服务，在启动之前需要添加一下启动参数  参数：-Ddubbo.resolve.file 值：dubbo-local.properties文件的本地地址，绝对地址  ps.当你不想连接本地服务调试时，只需将启动参数去掉即可，无需修改配置文件，让配置文件一直保持清爽干净。 以后你就可以安心的本地调试你的程序了，再也不会因为服务没有Export出去、配置文件被修改而焦头烂额。</description>
    </item>
    
    <item>
      <title>分支(branche)开发，主干(trunk)发布</title>
      <link>https://ningyu1.github.io/site/post/08-svn-trunk-branche/</link>
      <pubDate>Tue, 20 Dec 2016 14:32:41 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/08-svn-trunk-branche/</guid>
      <description>主干，分支分开开发模式在使用的时候要注意，主干是不做任何代码修改，只负责merge，修改全在分支上，不管是新功能的开发分支，还是修复bug的分支，如果线上有紧急bug修复，要先容trunk上拉一个bugfix分支出来，修改提交然后在merge到主干上去 ，打包测试发包。
图示：
注意事项： 本地修改的代码不要藏在本地 不提交，如果发现没有地方可以提交，提交会影响版本发布，那就是主干、分支开发模式使用不当，请及时调整</description>
    </item>
    
    <item>
      <title>SVN设置文件忽略的多种方法</title>
      <link>https://ningyu1.github.io/site/post/10-svn-ignore/</link>
      <pubDate>Sat, 26 Nov 2016 10:30:34 +0000</pubDate>
      
      <guid>https://ningyu1.github.io/site/post/10-svn-ignore/</guid>
      <description>方法一： 在svn客户端（小乌龟），想设置忽略提交.class文件，通过 properties -&amp;gt; New -&amp;gt; Other 添加一个忽略的属性，，还是不行：部分屏蔽了，部分class还是在列表中
方法二： 在svn客户端（小乌龟）：Settings -&amp;gt; General -&amp;gt; Global ignore pattern 添加了一个 *.class就行了
方法三： 在 Eclipse 中点击菜单 window -&amp;gt; Preferences -&amp;gt; Team -&amp;gt; Ignored Resources
点击 Add Pattern… 按钮添加你要忽略的文件或目录
方法四： 在Eclipse的导航视图中，选中尚未加入版本控制的文件或目录，右键 -&amp;gt; Team -&amp;gt; 添加至SVN:ignore
方法五： 在资源管理器中，右键一个未加入版本控制文件或目录，并从弹出菜单选择TortoiseSVN -&amp;gt; Add to Ignore List，会出现一个子菜单，允许你仅选择该文件或者所有具有相同后缀的文件。
如果你想从忽略列表中移除一个或多个条目，右击这些条目，选择TortoiseSVN -&amp;gt; 从忽略列表删除。</description>
    </item>
    
  </channel>
</rss>